# MULTIINSTRUCT: Improving Multi-Modal Zero-Shot Learning viaInstruction Tuning

## ***太长不看版***

作者工作重点是通过指令调优（instruction tuning）来提高各种未见过的多模态任务的泛化能力和零样本性能。作者创立了`MULTIINSTRUCT` 是个框架或数据集，旨在将多种任务转化为自然语言序列到序列（sequence-to-sequence）生成问题。这种转化方式允许模型根据给定的输入和指令来生成相应的输出。这种框架特别适用于那些涉及图像和文本的任务，其中模型需要理解和执行复杂的指令来产生适当的响应。

## **摘要**

指令调优是一种新的学习范式，通过对指令指定的任务进行微调，对预训练的语言模型进行优化。它在各种自然语言处理任务中表现出了有前途的零样本性能。然而，对于视觉和多模态任务，指令调优尚未得到探索。在这项工作中，我们介绍了MULTIINSTRUCT，这是第一个多模态指令调优基准数据集，由62个多样化的多模态任务组成，以统一的序列到序列格式覆盖10个广泛的类别。这些任务来自21个现有的开源数据集，每个任务都配备了5个专家撰写的指令。我们以OFA（Wang等人，2022a）作为多模态指令调优的基础预训练模型，并为了进一步提高其零样本性能，我们探索了多种迁移学习策略，以利用大规模的NATURAL INSTRUCTIONS数据集（Mishra等人，2022）。实验结果表明，在各种未见过的多模态任务上表现出强大的零样本性能，并从仅文本的指令数据集中迁移学习的益处。我们还设计了一个新的评估指标——敏感度，以评估模型对指令多样性的敏感度。我们的结果表明，对一组多样化的任务和指令进行微调会导致每个任务对指令变化的敏感度降低。



## 1  **引言**

随着大规模预训练语言模型（PLMs）的发展，最近的研究探索了各种有效的学习范式（Brown等人，2020；Liu等人，2021；Wei等人，2021；Xie等人，2021），以便在没有特定任务调优的情况下将PLMs推广到新任务。在这些范式中，指令调优（instruction tuning）（Wei等人，2021）在自然语言处理任务的零样本学习中取得了显著的成功。通过在通过指令描述的任务上对PLM进行微调，指令调优允许模型学会理解和遵循指令，以对未见过的任务进行预测。多模态预训练（Wang等人，2022a；Alayrac等人，2022；Bao等人，2022；Wang等人，2022c）的最新进展已经显示出在共享语义空间中联合解释文本和图像的潜力，这进一步引导我们提问：指令调优能否被利用来提高视觉语言预训练模型在多模态和视觉任务上的泛化能力？

在这项工作中，我们提出了MULTIINSTRUCT，这是第一个用于多模态指令调优的基准数据集，包含来自10个广泛类别的62个多样化任务，包括视觉问答（Goyal等人，2017；Suhr等人，2017）、常识推理（Zellers等人，2019；Xie等人，2019）、视觉关系理解（Krishna等人，2017）等。我们为每个任务配备了5条由两位自然语言处理专家撰写的指令。如图1所示，我们将所有任务统一为序列到序列的格式，其中输入文本、图像、指令和边界框都在相同的令牌空间中表示。

我们使用OFA（Wang等人，2022a）2作为基础预训练的多模态语言模型，OFA是一个统一模型，它在单个基于Transformer的序列到序列框架中对多种多模态和单模态任务进行了预训练。我们在MULTIINSTRUCT上对其进行微调。为了利用NATURAL INSTRUCTIONS（Mishra等人，2022）数据集来提高指令调优的效果，我们探索了多种迁移学习策略。

实验结果表明，在各种未见过的多模态任务上，该模型表现出强大的零样本性能，并且从仅文本的指令数据集中迁移学习也带来了好处。此外，我们还设计了一个新的评估指标——敏感度，以评估模型对指令多样性的敏感度。我们的结果表明，对一组多样化的任务和指令进行微调会导致每个任务对指令变化的敏感度降低。



## 2  **相关工作**

**模态预训练**：多模态预训练（Tan和Bansal，2019；Cho等人，2021；Singh等人，2022；Alayrac等人，2022；Wang等人，2022a；Li等人，2022b，a）在视觉语言任务方面取得了显著的进展。最近的一些研究（Cho等人，2021；Wang等人，2022a，c；Lu等人，2022）也开始构建一个统一的预训练框架来处理多样化的跨模态和单模态任务。其中，VL-T5（Cho等人，2021）使用了一个统一的文本生成目标，该目标根据多模态输入处理视觉和语言任务，而OFA（Wang等人，2022a）则通过为所有文本和视觉tokens使用统一的词汇表，进一步将其扩展到图像生成任务。BEIT-3（Wang等人，2022c）利用一个具有共享自注意力模块的新型共享多路Transformer网络来对齐不同的模态并提供深度融合。在我们的工作中，我们建立在多模态预训练的成功基础上，重点是通过指令调优来提高各种未见过的多模态任务的泛化能力和零样本性能。

**高效的语言模型调优**：为了提高大规模预训练语言模型的泛化能力和适应性，最近提出了各种高效的语言模型调优策略。提示调优（Liu等人，2021；Li和Liang，2021；Han等人，2022；Wang等人，2022b；Sanh等人，2022）旨在通过学习特定任务的提示来将下游任务重新表述为模型最初训练的格式，并在各种自然语言处理应用中显示出竞争性的性能。作为提示调优的一种特殊形式，上下文学习（Xie等人，2021；Min等人，2021）将一个或几个示例作为提示来演示任务。指令调优（Wei等人，2021）是另一种简单而有效的策略，用于提高大型语言模型的泛化能力。NATURAL INSTRUCTIONS（Mishra等人，2022）是一个元数据集，包含各种自然语言指令和对应的数据集，用于指导模型学习执行各种任务。

## **3 MULTIINSTRUCT**

**3.1 多模态任务与数据收集**

MULTIINSTRUCT 数据集旨在涵盖一系列需要跨区域、图像和文本进行推理的多模态任务。这些任务旨在教导机器学习模型遵循指令执行各种任务，如物体识别、视觉关系理解、文本-图像对齐等，从而使模型能够在未见过的任务上进行零样本预测。为了构建 MULTIINSTRUCT，我们首先从视觉和多模态学习的现有研究中收集了 34 个任务，涵盖视觉问答（Goyal 等人，2017；Krishna 等人，2017；Zhu 等人，2016；Hudson 和 Manning，2019；Singh 等人，2019；Marino 等人，2019）、常识推理（Suhr 等人，2017；Liu 等人，2022a；Zellers 等人，2019；Xie 等人，2019）、区域理解（Krishna 等人，2017）、图像理解（Kafle 和 Kanan，2017；Chiu 等人，2020）、基础生成（Krishna 等人，2017；Yu 等人，2016；Lin 等人，2014）、图像-文本匹配（Lin 等人，2014；Goyal 等人，2017）、基础匹配（Krishna 等人，2017；V eit 等人，2016；Yu 等人，2016）、视觉关系（Krishna 等人，2017；Pham 等人，2021）、从 WikiHow3 创建的时间排序任务，以及其他各种任务（Yao 等人，2022；Kiela 等人，2020；Das 等人，2017；Lin 等人，2014；V eit 等人，2016；Alam 等人，2022）。这 34 个任务中的每一个都可以在一个或多个开源数据集中找到，这些数据集被整合到 MULTIINSTRUCT 中。每个任务及其对应数据集的详细信息见附录中的表 7 至 9。

对于这些任务中的每一个，我们进一步研究了基于原始任务的输入和输出生成新任务的可能性，以增加任务库。例如，视觉定位需要模型为图像中的给定区域生成标题。我们从中得出了两个额外的任务：基于标题的定位选择，这是一个更简单的任务，需要模型从多个候选者中为给定的区域选择相应的标题；视觉定位选择，这需要模型根据给定的标题从提供的候选区域中选择相应的区域。与视觉定位相比，这两个新任务需要基于不同的输入和输出信息，需要不同的技能。这样，我们从34个现有任务中进一步推导出了28个新任务。我们将所有62个任务分为10个大类，如图2所示。

对于现有任务，我们使用它们可用的开源数据集来创建实例（即输入和输出对）。而对于每个新任务，我们通过从现有任务的实例中提取必要的信息或重新组合它们来创建实例。每个新任务都创建了5000到5M个实例。我们根据以下标准将62个任务分为训练和评估任务：（1）我们采用与OFA（Wang等人，2022a）的预训练任务相似的任务进行训练；

*<u>这一步主要是为了利用迁移学习的优势。通过选择与OFA预训练任务相似的任务进行训练，模型可以更快地适应这些任务，因为OFA已经对这些类型的任务有了一定的理解。这种做法并不是直接验证零样本能力，因为它依赖于使用相似的任务进行训练。</u>*

（2）我们选择具有挑战性的多模态任务进行评估，这些任务与训练任务不重叠。附录A中的表5和表6显示了MULTIINSTRUCT中训练和评估任务的详细统计信息，而表7到表9则显示了它们对应的数据集。

<u>*选择不与训练任务重叠的任务进行评估是为了确保评估结果的公正性和模型在未见过的任务上的表现。这种评估方式更接近于零样本学习的概念，因为模型需要在没有额外训练的情况下处理全新的任务。然而，这并不意味着这些任务必须是完全零样本的，因为模型可能已经在相似的任务上进行了训练，从而获得了某种程度的泛化能力。*</u>

 

**3.2 任务指令创建**

我们首先为MULTIINSTRUCT中使用的“指令”提供了一个定义。指令是用模板定义的，描述了任务应该如何执行，并包含任意数量的占位符，包括<TEXT>、<REGION>和<OPTION>，用于来自原始任务的输入信息。例如，在“为<REGION>生成标题”的Grounded Captioning任务指令中，<REGION>是特定区域信息的占位符。请注意，占位符<OPTION>仅用于分类任务，并且对于某些任务，输入可能还包括指令中未包含的图像，该图像将作为单独的输入提供给模型。图1提供了MULTIINSTRUCT中包含的任务的几个指令示例。

为了产生高质量且能准确传达预定任务的指令，我们采用了涉及两位对该任务和数据集有深入了解的专家标注者的迭代标注过程。

第一步：每位标注者首先根据任务的具体目标、输入数据的格式，以及从数据集中随机抽取的10个示例实例，为每个任务编写2-3条指令。关于数据集的信息从数据集的README文件或介绍数据集的出版物中获得。对于新派生的任务，我们向标注者提供任务描述以及10个构建的示例实例。

第二步：为了保证指令的质量和它们能有效地传达预定任务，我们要求每位标注者审查其同伴创建的指令，检查是否只需阅读指令就能清楚地理解和识别预定任务。如果发现任何问题，审查的标注者会提供建议并与原始标注者合作修订指令。

第三步：为了确保一致性，避免不同标注者之间指令的冲突或重复，我们要求两位标注者一起审查指令集，识别任何差异或不一致之处。如果找到任何差异，标注者会协作解决它们，并创建一套准确且清晰地描述任务的最终指令。这样，每个任务都将使用5条高质量的指令创建。

第四步：我们重复步骤1-3，为每个训练和评估任务创建5条指令。最后，两位标注者审查每个任务及其指令，并过滤掉不具代表性或与其他任务重叠的任务。



**3.3 多模态指令格式**

为了统一处理各种输入/输出数据类型，我们遵循OFA（Wang等人，2022a）的方法，该方法将图像、文本和边界框坐标表示为统一词汇表中的令牌。具体来说，我们应用字节对编码（BPE）（Sennrich等人，2016）来编码文本输入。对于目标图像，我们应用VQ-GAN（Esser等人，2021）通过图像量化生成离散的图像令牌。为了表示图像的区域或边界框，我们将四个角坐标离散化为位置令牌，如"<bin_242> <bin_180> <bin_736> <bin_475>"，其中每个位置令牌"<bin_NUM>"表示通过将图像划分为1000个bin而获得的量化坐标。这种方法允许我们将不同类型的输入转换为统一词汇表。

然后，MULTIINSTRUCT中的所有任务都可以表述为自然语言序列到序列的生成问题，其中输入包括：（1）图像（如果没有输入图像，则使用黑色图片作为输入）；（2）指令，其中占位符（如<TEXT>、<REGION>或<OPTION>）填充为每个输入实例的特定信息。值得注意的是，对于分类任务的指令中的<OPTION>，我们为此字段引入了两个特殊令牌：“[Options]”来标记选项字段的开始，以及“||||”来分隔给定的选项。我们将所有选项用“||||”连接在选项字段中，模型将直接从它们中生成一个选项。图1提供了几个表述的输入示例，并说明了如何将原始数据输入与MULTIINSTRUCT中的指令相结合。

`MULTIINSTRUCT` 是一个框架或数据集，旨在将多种任务转化为自然语言序列到序列（sequence-to-sequence）生成问题。这种转化方式允许模型根据给定的输入和指令来生成相应的输出。这种框架特别适用于那些涉及图像和文本的任务，其中模型需要理解和执行复杂的指令来产生适当的响应。



<u>*笔记：*</u>

<u>*在 `MULTIINSTRUCT` 中，每个任务都可以这样描述：*</u>

1. <u>***输入**：*</u>


	* **图像**：如果存在输入图像，则使用该图像作为输入；如果没有输入图像，则使用一个黑色的图片作为输入。
	* **指令**：这是一个描述任务具体要求的自然语言句子。指令中可能包含一些占位符，如 `<TEXT>`、`<REGION>` 或 `<OPTION>`，这些占位符在具体任务实例中会被具体信息所替代。
2. <u>***指令中的特殊标记**：*</u>


	* 对于分类任务中的 `<OPTION>` 占位符，引入了两个特殊的标记：`[Options]` 用于标记选项字段的开始，而 `||||` 用于分隔给定的选项。这些选项会通过 `||||` 连接在一起，模型会直接从这些选项中生成一个作为输出。
3. <u>***模型的工作方式**：*</u>


	* 模型接收这种格式化的输入，并根据指令和提供的信息生成相应的输出。例如，如果指令要求模型根据图像中的某个区域进行分类，模型就会查看图像中指定的区域，并从提供的选项中选择一个作为输出。
4. <u>***示例**：*</u>


	* 图1提供了几个这样的示例，展示了如何将原始数据输入与 `MULTIINSTRUCT` 中的指令结合起来。这些示例有助于理解这种框架是如何工作的，以及它如何能够处理不同类型和复杂度的任务。



## 4 问题设置和模型

**4.1 问题设置**

我们遵循与之前研究相同的指令调优设置(Wei et al .， 2021)，主要评估调优后的大型语言模型的零次学习能力。具体来说，给定一个预训练的多模态语言模型M，我们的目标是在一系列指令任务T上对其进行微调。每个任务t∈T与多个训练实例相关联Dt = {(It, xtj, ytj)∈It × X t × Yt}Nj=1，其中xtj表示输入的文本、图像、区域和提供的选项，ytj表示每个实例的输出，表示专家编写的五个任务指令的集合。来自xtj的输入信息将用于填充指令中的占位符。

我们使用OFA (Wang et al .， 2022a)作为预训练的多模态模型，因为它具有统一的架构和灵活的输入输出模式。我们在multidirective数据集上对其进行了调优，以证明指令调优的有效性。

灵活的输入输出模式：*<u>包括支持不同的输入数据类型（如图像、文本、音频等）、不同的输入尺寸和分辨率，以及不同的输出类型和格式</u>*

具体来说，我们使用OFA的基于变压器的编码器对指令以及所有必要的信息和可选图像进行编码，并使用基于变压器的解码器预测输出。考虑到训练数据集包含许多任务，我们将这些任务中的所有训练实例混合并随机洗牌。对于每个实例，我们还为每个基于批处理的训练随机抽取一个指令模板。注意，虽然multidirective中的一些训练任务类似于OFA4的预训练任务，但我们确保multidirective中的评估任务既不与OFA中的预训练任务重叠，也不与multidirective中的训练任务重叠。

**4.2从自然指令中迁移学习**

我们注意到，自然指令的规模(Mishra et al .， 2022)明显大于multiinstruction，这表明将指令学习能力从更大的自然语言任务集转移到多模态任务的潜力。我们在NATURAL INSTRUCTIONS中使用了832个英语任务，并探索了几种简单的迁移学习策略:

混合指令调优(ofamixedinstruction)

我们将自然指令(NATURAL Instruction)和多指令(multiinstruction)的实例组合在一起，在用指令调优OFA之前随机对它们进行洗牌。请注意，NATURAL INSTRUCTIONS中的每个任务仅与一条指令相关联，而对于multidirective的每个实例，我们总是从每个训练实例的五个指令中随机抽取一条指令。

顺序指令调优

受Aghajanyan等人(2021)中讨论的预微调方法的启发，我们提出了一个两阶段的顺序指令调整策略，我们首先在自然指令数据集上微调OFA，以鼓励模型遵循指令执行仅语言任务，然后在multidirective上进一步微调，以使指令学习能力适应多模态任务。为了最大限度地提高自然指令数据集的有效性，我们在第一个训练阶段使用英语任务中的所有实例来调整模型。

## 5  实验设置

**5.1评估矩阵**

我们报告了分类任务和ROUGE-L (Lin, 2004)对所有生成任务的准确性。对于区域分类任务，我们计算生成的区域与选项中所有区域之间的Intersection over Union (IoU)，选择IoU最高的选项作为预测，并根据该预测计算精度。如果预测的区域与选项中的任何区域都没有交集，我们将此预测视为不正确。对于答案不是单字二元分类的分类任务，我们还报告了遵循Mishra等人(2022)的ROUGE-L分数，Mishra等人将所有任务视为文本生成问题。对于每个任务，我们通过在每个实验中使用五个指令中的一个来评估模型，进行五个实验。我们报告五个实验的平均性能和最大性能以及性能的标准偏差移植。我们还根据模型在所有多模态和NLP未见任务上的性能平均值计算每个模型的聚合性能。我们使用Rouge-L作为大多数任务的评估指标，使用精确度作为仅以精确度为指标的任务的评估指标。

此外，由于指令调优主要依赖指令来引导模型对各种看不见的多模态任务进行预测，我们进一步提出评估模型对同一任务中各种人工编写指令的敏感性，这在以前的指令调优研究中没有讨论，但对于理解指令调优的有效性是必要的。





o 四.方法(二级标题)(我们的笔记 遵从原文的小节展开 即可)
4.1(三级标题)
4.2
4.3
o五.实验(二级标题)(下面几个小节，只是格式示例，我们的笔记跟随原文即可)
setting(三级标题)
mresult
mablation
case analyse
o 六.结论(二级标题)